# -*- coding: utf-8 -*-
"""Clasificador de perros y gatos_SBR

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jZKBnXjZIC427HIn2HW_viw1pC3v5Zmm
"""

#!pip install tensorflowjs

"""# Librerias"""

import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import pandas as pd
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
#from tensorflow.keras.models import Sequential
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
#from tensorflow.keras.preprocessing.image import ImageDataGenerator
#from tensorflow.keras.callbacks import TensorBoard
import itertools
from sklearn.metrics import confusion_matrix

"""# Funciones para graficar"""

def plot_training(hist):
    '''
    This function take training model and plot history of accuracy and losses with the best epoch in both of them.
    '''

    # Define needed variables
    tr_acc = hist.history['accuracy']
    tr_loss = hist.history['loss']
    val_acc = hist.history['val_accuracy']
    val_loss = hist.history['val_loss']
    index_loss = np.argmin(val_loss)
    val_lowest = val_loss[index_loss]
    index_acc = np.argmax(val_acc)
    acc_highest = val_acc[index_acc]
    Epochs = [i+1 for i in range(len(tr_acc))]
    loss_label = f'best epoch= {str(index_loss + 1)}'
    acc_label = f'best epoch= {str(index_acc + 1)}'

    # Plot training history
    plt.figure(figsize= (20, 8))
    plt.style.use('fivethirtyeight')

    plt.subplot(1, 2, 1)
    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')
    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')
    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')
    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')
    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout
    plt.show()
    plt.savefig(f'training_{hist}.jpg')

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):
    '''
    This function plot confusion matrix method from sklearn package.
    '''

    plt.figure(figsize=(10, 10))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print('Normalized Confusion Matrix')
    else:
        print('Confusion Matrix, Without Normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j], horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')

    plt.tight_layout()
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')

    plt.show()
    plt.savefig(f'confusion_matrix_{title}.jpg')

"""# Descarga de datos"""

#Correccion temporal (22/mayo/2022)
#Tensorflow datasets tiene error al descargar el set de perros y gatos y lo solucionaron
#el 16 de mayo pero sigue fallando en los colabs. Entonces se agrega esta linea adicional
#Mas detalle aqui: https://github.com/tensorflow/datasets/issues/3918
setattr(tfds.image_classification.cats_vs_dogs, '_URL',"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip")

#Descargar el set de datos de perros y gatos
datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)

#Imprimir los metadatos para revisarlos
metadatos

#Una forma de mostrar 5 ejemplos del set
tfds.as_dataframe(datos['train'].take(5), metadatos)

#Otra forma de mostrar ejemplos del set
tfds.show_examples(datos['train'], metadatos)

#Manipular y visualizar el set
#Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)

plt.figure(figsize=(20,20))

TAMANO_IMG=100

for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):
  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  plt.subplot(5, 5, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(imagen, cmap='gray')

#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)
datos_entrenamiento = []

"""# Manejo de datos"""

for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos
  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))
  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1
  datos_entrenamiento.append([imagen, etiqueta])

#Ver los datos del primer indice
datos_entrenamiento[0]

#Ver cuantos datos tengo en la variable
len(datos_entrenamiento)

#Preparar mis variables X (entradas) y y (etiquetas) separadas

X = [] #imagenes de entrada (pixeles)
y = [] #etiquetas (perro o gato)

for imagen, etiqueta in datos_entrenamiento:
  X.append(imagen)
  y.append(etiqueta)

X

#Normalizar los datos de las X (imagenes). Se pasan a numero flotante y dividen entre 255 para quedar de 0-1 en lugar de 0-255

X = np.array(X).astype(float) / 255

y

#Convertir etiquetas en arreglo simple
y = np.array(y)

X.shape

# 1. División inicial: 70% train / 30% temp (val + test)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y,
    test_size=0.3,
    random_state=10,
    stratify=y  # Mantiene proporción de clases
)

# 2. División del 30% temp: 15% validation / 15% test
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=0.5,
    random_state=10,
    stratify=y_temp
)

# Verificación de tamaños
print(f"Entrenamiento: {len(X_train)} imágenes")
print(f"Validación: {len(X_val)} imágenes")
print(f"Prueba: {len(X_test)} imágenes")

# Verificación de proporciones
print("\nProporción de clases en cada conjunto:")
print(f"Train - Gatos: {np.sum(y_train == 0)}, Perros: {np.sum(y_train == 1)}")
print(f"Val - Gatos: {np.sum(y_val == 0)}, Perros: {np.sum(y_val == 1)}")
print(f"Test - Gatos: {np.sum(y_test == 0)}, Perros: {np.sum(y_test == 1)}")

'''
# Aumento de datos
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=15,
    zoom_range=[0.7, 1.4],
    horizontal_flip=True,
    vertical_flip=True
)

# Ajustar el generador a los datos de entrenamiento
datagen.fit(X_train)
'''

"""# Modelos

## Red Neuronal Regular
"""

# Construcción del modelo
model_rr = tf.keras.models.Sequential([
    Flatten(input_shape=(100, 100, 1)),  # Aplanar la imagen de 100x100x1
    Dense(256, activation='relu', kernel_regularizer=l2(0.001)), # Capa oculta con regularización L2
    BatchNormalization(), # Normalización por lotes
    Dropout(0.5), # Dropout para evitar overfitting
    Dense(128, activation='relu', kernel_regularizer=l2(0.001)), # Otra capa oculta
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation='relu', kernel_regularizer=l2(0.001)), # Otra capa oculta
    BatchNormalization(),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Capa de salida
])

# Compilación del modelo
model_rr.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Entrenamiento del modelo
history_rr = model_rr.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_val, y_val),
)

'''
# Para aumento de datos
history_rr = model_rr.fit(
    datagen.flow(X_train, y_train, batch_size=32), # Usar el generador de aumento de datos
    epochs=100,
    validation_data=(X_val, y_val),
)
'''

# Evaluación del modelo
loss_rr, accuracy_rr = model_rr.evaluate(X_test, y_test)
print(f'Test Loss: {loss_rr}')
print(f'Test Accuracy: {accuracy_rr}')

# Genera predicciones (probabilidades)
y_pred_prob_rr = model_rr.predict(X_test)

# Convierte las probabilidades a clases binarias (0 o 1)
y_pred_rr = (y_pred_prob_rr > 0.5).astype(int)

# Calcula la matriz de confusión
cm_rr = confusion_matrix(y_test, y_pred_rr)

# Define las clases (0: Gato, 1: Perro)
class_names = ['Gato', 'Perro']

# Graficar precision y perdida
plot_training(history_rr)

# Graficar matriz de confusion
plot_confusion_matrix(cm_rr, classes=class_names, title = 'Matriz de Confusión - Red Neuronal Regular')

"""## Red Neuronal Convolucional (CNN)"""

# Construcción del modelo
model_cnn = tf.keras.models.Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1), kernel_regularizer=l2(0.001)), # Primera capa convolucional
    BatchNormalization(),
    MaxPooling2D(2, 2), # Capa de pooling
    Dropout(0.25), # Dropout después de pooling

    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)), # Segunda capa convolucional
    BatchNormalization(),
    MaxPooling2D(2, 2),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)), # Tercera capa convolucional
    BatchNormalization(),
    MaxPooling2D(2, 2),
    Dropout(0.25),

    Flatten(),  # Aplanar las características
    Dense(512, activation='relu', kernel_regularizer=l2(0.001)), # Capa completamente conectada
    BatchNormalization(),
    Dropout(0.5), # Dropout antes de la capa de salida
    Dense(1, activation='sigmoid') # Capa de salida
])

# Compilación del modelo
model_cnn.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Entrenamiento del modelo
history_cnn = model_cnn.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_val, y_val),
)

'''
# Para aumento de datos
history_cnn = model_cnn.fit(
    datagen.flow(X_train, y_train, batch_size=32),  # Usar el generador de aumento de datos
    epochs=100,
    validation_data=(X_val, y_val),
)
'''

# Evaluación del modelo
loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test, y_test)
print(f'Test Loss: {loss_cnn}')
print(f'Test Accuracy: {accuracy_cnn}')

# Genera predicciones (probabilidades)
y_pred_prob_cnn = model_cnn.predict(X_test)

# Convierte las probabilidades a clases binarias (0 o 1)
y_pred_cnn = (y_pred_prob_cnn > 0.5).astype(int)

# Calcula la matriz de confusión
cm_cnn = confusion_matrix(y_test, y_pred_cnn)

# Define las clases (0: Gato, 1: Perro)
class_names = ['Gato', 'Perro']

# Graficar precision y perdida
plot_training(history_cnn)

# Graficar matriz de confusion
plot_confusion_matrix(cm_cnn, classes=class_names, title = 'Matriz de Confusión - Red Neuronal Convolucional (CNN)')

"""# Guardar modelos"""

model_rr.save('perros-gatos-rr.h5')

model_cnn.save('perros-gatos-cnn.h5')

'''
!tensorflowjs_converter --input_format=keras \
                       --output_format=tfjs_layers_model \
                       perros-gatos-rr.h5 \
                       tfjs_model_rr
'''

'''
!tensorflowjs_converter --input_format=keras \
                       --output_format=tfjs_layers_model \
                       perros-gatos-cnn.h5 \
                       tfjs_model_cnn
'''